{"Id": "71001123", "PostTypeId": "1", "CreationDate": "2022-02-05T18:50:18.653", "Score": "2", "ViewCount": "842", "Body": "<p>tldr; I can deploy a single CFN stack as part of my pipeline, but how do I deploy multiple dynamic stacks?</p>\n<p>An even better tldr; How would you do this? forEach BuildStage.artifact invoke CloudFormation.build</p>\n<p>I am using CodePipeline in a pretty conventional way. The goal is to source control my CloudFormation templates, push them through the pipeline when a template changes, and then automatically deploy the stack.</p>\n<p>Source Stage (CodeCommit commit my CFN yaml templates)</p>\n<p>Build Stage (CodeBuild finds the new files from the commit, and pushes them to S3)</p>\n<p>Deploy Stage (CloudFormation deploys my templates as CFN stacks)</p>\n<p><em>Almost</em> everything is working great. I commit my template changes to CodeCommit, the build stage runs my codeBuild gatekeeper, which gathers <strong>only</strong> the files that have changed, and uploads them to S3. So far so good.</p>\n<p>The challenge is that sometimes I have one template change, and sometimes I have multiple(n). I can detect changed files and get them up to S3 no problem in my build stage. If I commit a change for one template, everything works fine. I can create an exported variable with my template location on S3, pass that to my deploy stage, and have the CloudFormation deploy action use that file as the template source. But how would I handle this if I have 2 templates?</p>\n<ul>\n<li>I can't just create endless exported variables in my build stage.</li>\n<li>And if I can, AFAIK there is no way to iterate over each entry for the deploy stage.</li>\n</ul>\n<p>My thought is I would need to do one of the following:</p>\n<ol>\n<li>Inside of my current buildspec (after I upload the files to S3), use the AWS CLI to invoke a CFN stack build. I can add this as part of a loop, so it iterates on each file to be uploaded.  OR</li>\n<li>After my build stage, use a Lambda to perform the same as #1. Loop through each file, and then use the CLI or SDK to invoke a CFN stack build.</li>\n</ol>\n<p>Both of these options seem to defeat the purpose of the deploy stage altogether, which seems clunky to me.</p>\n<p>Are there other options I am missing? What would you do?</p>\n", "OwnerUserId": "6046710", "LastEditorUserId": "6046710", "LastEditDate": "2022-02-05T20:52:05.660", "LastActivityDate": "2022-10-10T11:50:05.133", "Title": "CodePipeline how to deploy multiple CFN stacks", "Tags": "|amazon-web-services|aws-cloudformation|aws-codepipeline|aws-codebuild|", "AnswerCount": "1", "CommentCount": "5", "ContentLicense": "CC BY-SA 4.0", "comments": [{"Id": "125515425", "PostId": "71001123", "Score": "0", "Text": "Wouldn't adding another deploy stage for the second template work?", "CreationDate": "2022-02-05T20:03:34.007", "UserId": "1526347", "filtered-sentences": []}, {"Id": "125515664", "PostId": "71001123", "Score": "2", "Text": "@jingx - Maybe that could work if I know about the second template in advance. But what if only one template is committed? What if 10 templates are committed? I almost need a way to be able to dynamically scale the deploy stage. Though I feel like that might be the wrong approach or I am missing something and it is actually really easy :-D", "CreationDate": "2022-02-05T20:23:36.377", "UserId": "6046710", "filtered-sentences": []}, {"Id": "125517369", "PostId": "71001123", "Score": "0", "Text": "Are you saying the number of templates can change from build to build? or just the number of _changed_ templates can change?  If it's the later you shouldn't have to worry about excluding unchanged templates, CFN detects changes on itself.", "CreationDate": "2022-02-05T22:49:08.213", "UserId": "1526347", "filtered-sentences": [{"source": "Text", "text": "Are you saying the number of templates can change from build to build? or just the number of _changed_ templates can change? ", "keywords": ["change"]}, {"source": "Text", "text": "If it's the later you shouldn't have to worry about excluding unchanged templates, CFN detects changes on itself.", "keywords": ["change"]}]}, {"Id": "125519208", "PostId": "71001123", "Score": "0", "Text": "Honestly, both. Right now I might have a total of 10 templates in my repo, and maybe they all change one at a time. But it is possible for 1) more templates to be added to the repo, and 2) more than one template to be changed per commit.", "CreationDate": "2022-02-06T02:43:10.293", "UserId": "6046710", "filtered-sentences": [{"source": "Text", "text": "Right now I might have a total of 10 templates in my repo, and maybe they all change one at a time. ", "keywords": ["change"]}, {"source": "Text", "text": "But it is possible for 1) more templates to be added to the repo, and 2) more than one template to be changed per commit.", "keywords": ["change"]}]}, {"Id": "125587074", "PostId": "71001123", "Score": "0", "Text": "You need to use the CDK or Bisque to generate the template for your pipeline.  There is no out of the box solution for looping or foreach.", "CreationDate": "2022-02-09T00:38:42.020", "UserId": "168589", "filtered-sentences": []}], "history": [{"Id": "263505803", "PostHistoryTypeId": "5", "PostId": "71001123", "RevisionGUID": "3f240522-8d3c-47db-bbdf-68ddf586423d", "CreationDate": "2022-02-05T20:37:36.437", "UserId": "6046710", "Comment": "added 104 characters in body", "Text": "tldr; I can deploy a single CFN stack as part of my pipeline, but how do I deploy multiple dynamic stacks?\r\n\r\nAn even better tldr; How would you do this? forEach BuildStage.artifact invoke CloudFormation.build \r\n\r\n\r\nI am using CodePipeline in a pretty conventional way. The goal is to source control my CloudFormation templates, push them through the pipeline when a template changes, and then automatically deploy the stack. \r\n\r\nSource Stage (CodeCommit check-in CFN yaml templates)\r\n\r\nBuild Stage (CodeBuild finds the new files from the commit, and pushes them to S3)\r\n\r\nDeploy Stage (CloudFormation deploys my templates as CFN stacks)\r\n\r\n*Almost* everything is working great. I check-in to CodeCommit, the build stage runs my gatekeeper build and gathers only the files that have changed, and uploads them to S3. So far so good. \r\n\r\nThe challenge is that sometimes I have one template change, and sometimes I have multiple(n). I can detect changed files and get them up to S3 no problem in my build stage. If I commit a change for one template, everything works fine. I can create an exported variable with my template location on S3, pass that to my deploy stage, and have the CloudFormation deploy action use that file as the template source. But how would I handle this if I have 2 templates? \r\n\r\n - I can't just create endless exported variables in my build stage.\r\n - And if I can, AFAIK there is no way to iterate over each entry for the deploy stage.\r\n\r\nMy thought is I would need to do one of the following:\r\n\r\n 1. Inside of my current buildspec (after I upload the files to S3), use the AWS CLI to invoke a CFN stack build. I can add this as part of a loop, so it iterates on each file to be uploaded.  OR\r\n 2. After my build stage, use a Lambda to perform the same as #1. Loop through each file, and then use the CLI or SDK to invoke a CFN stack build.\r\n\r\nBoth of these options seem to defeat the purpose of the deploy stage altogether, which seems clunky to me. \r\n\r\nAre there other options I am missing? What would you do?\r\n\r\n", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "The goal is to source control my CloudFormation templates, push them through the pipeline when a template changes, and then automatically deploy the stack. ", "keywords": ["change"]}, {"source": "Text", "text": "I check-in to CodeCommit, the build stage runs my gatekeeper build and gathers only the files that have changed, and uploads them to S3. ", "keywords": ["change"]}, {"source": "Text", "text": "The challenge is that sometimes I have one template change, and sometimes I have multiple(n). ", "keywords": ["change"]}, {"source": "Text", "text": "I can detect changed files and get them up to S3 no problem in my build stage. ", "keywords": ["change"]}, {"source": "Text", "text": "If I commit a change for one template, everything works fine. ", "keywords": ["change"]}]}, {"Id": "263501764", "PostHistoryTypeId": "2", "PostId": "71001123", "RevisionGUID": "979bd715-7e44-4174-ab21-2d1f541ad375", "CreationDate": "2022-02-05T18:50:18.653", "UserId": "6046710", "Text": "tldr; I can deploy a single CFN stack as part of my pipeline, but how do I deploy multiple dynamic stacks?\r\n\r\n\r\nI am using CodePipeline in a pretty conventional way. The goal is to source control my CloudFormation templates, push them through the pipeline when a template changes, and then automatically deploy the stack. \r\n\r\nSource Stage (CodeCommit check-in CFN yaml templates)\r\n\r\nBuild Stage (CodeBuild finds the new files from the check-in, and pushes them to S3)\r\n\r\nDeploy Stage (CloudFormation deploys my templates as CFN stacks)\r\n\r\n*Almost* everything is working great. I check-in to CodeCommit, the build stage runs my gatekeeper build and gathers only the files that have changed, and uploads them to S3. So far so good. \r\n\r\nThe challenge is that sometimes I have one template change, and sometimes I have multiple(n). I can detect changed files and get them up to S3 no problem in my build stage. If I commit a change for one template, everything works fine. I can create an exported variable with my template location on S3, pass that to my deploy stage, and have the CloudFormation deploy action use that file as the template source. But how would I handle this if I have 2 templates? \r\n\r\n - I can't just create endless exported variables in my build stage.\r\n - And if I can, AFAIK there is no way to iterate over each entry for the deploy stage.\r\n\r\nMy thought is I would need to do one of the following:\r\n\r\n 1. Inside of my current buildspec (after I upload the files to S3), use the AWS CLI to invoke a CFN stack build. I can add this as part of a loop, so it iterates on each file to be uploaded.  OR\r\n 2. After my build stage, use a Lambda to perform the same as #1. Loop through each file, and then use the CLI or SDK to invoke a CFN stack build.\r\n\r\nBoth of these options seem to defeat the purpose of the deploy stage altogether, which seems clunky to me. \r\n\r\nAre there other options I am missing? What would you do?\r\n\r\n", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "The goal is to source control my CloudFormation templates, push them through the pipeline when a template changes, and then automatically deploy the stack. ", "keywords": ["change"]}, {"source": "Text", "text": "I check-in to CodeCommit, the build stage runs my gatekeeper build and gathers only the files that have changed, and uploads them to S3. ", "keywords": ["change"]}, {"source": "Text", "text": "The challenge is that sometimes I have one template change, and sometimes I have multiple(n). ", "keywords": ["change"]}, {"source": "Text", "text": "I can detect changed files and get them up to S3 no problem in my build stage. ", "keywords": ["change"]}, {"source": "Text", "text": "If I commit a change for one template, everything works fine. ", "keywords": ["change"]}]}, {"Id": "263501766", "PostHistoryTypeId": "1", "PostId": "71001123", "RevisionGUID": "979bd715-7e44-4174-ab21-2d1f541ad375", "CreationDate": "2022-02-05T18:50:18.653", "UserId": "6046710", "Text": "CodePipeline how to deploy multiple CFN stacks", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "263501767", "PostHistoryTypeId": "3", "PostId": "71001123", "RevisionGUID": "979bd715-7e44-4174-ab21-2d1f541ad375", "CreationDate": "2022-02-05T18:50:18.653", "UserId": "6046710", "Text": "|amazon-web-services|aws-cloudformation|aws-codepipeline|aws-codebuild|", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "263502175", "PostHistoryTypeId": "5", "PostId": "71001123", "RevisionGUID": "b7b576e4-cf82-4733-b448-01bdf1813fde", "CreationDate": "2022-02-05T19:00:13.097", "UserId": "6046710", "Comment": "deleted 2 characters in body", "Text": "tldr; I can deploy a single CFN stack as part of my pipeline, but how do I deploy multiple dynamic stacks?\r\n\r\n\r\nI am using CodePipeline in a pretty conventional way. The goal is to source control my CloudFormation templates, push them through the pipeline when a template changes, and then automatically deploy the stack. \r\n\r\nSource Stage (CodeCommit check-in CFN yaml templates)\r\n\r\nBuild Stage (CodeBuild finds the new files from the commit, and pushes them to S3)\r\n\r\nDeploy Stage (CloudFormation deploys my templates as CFN stacks)\r\n\r\n*Almost* everything is working great. I check-in to CodeCommit, the build stage runs my gatekeeper build and gathers only the files that have changed, and uploads them to S3. So far so good. \r\n\r\nThe challenge is that sometimes I have one template change, and sometimes I have multiple(n). I can detect changed files and get them up to S3 no problem in my build stage. If I commit a change for one template, everything works fine. I can create an exported variable with my template location on S3, pass that to my deploy stage, and have the CloudFormation deploy action use that file as the template source. But how would I handle this if I have 2 templates? \r\n\r\n - I can't just create endless exported variables in my build stage.\r\n - And if I can, AFAIK there is no way to iterate over each entry for the deploy stage.\r\n\r\nMy thought is I would need to do one of the following:\r\n\r\n 1. Inside of my current buildspec (after I upload the files to S3), use the AWS CLI to invoke a CFN stack build. I can add this as part of a loop, so it iterates on each file to be uploaded.  OR\r\n 2. After my build stage, use a Lambda to perform the same as #1. Loop through each file, and then use the CLI or SDK to invoke a CFN stack build.\r\n\r\nBoth of these options seem to defeat the purpose of the deploy stage altogether, which seems clunky to me. \r\n\r\nAre there other options I am missing? What would you do?\r\n\r\n", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "The goal is to source control my CloudFormation templates, push them through the pipeline when a template changes, and then automatically deploy the stack. ", "keywords": ["change"]}, {"source": "Text", "text": "I check-in to CodeCommit, the build stage runs my gatekeeper build and gathers only the files that have changed, and uploads them to S3. ", "keywords": ["change"]}, {"source": "Text", "text": "The challenge is that sometimes I have one template change, and sometimes I have multiple(n). ", "keywords": ["change"]}, {"source": "Text", "text": "I can detect changed files and get them up to S3 no problem in my build stage. ", "keywords": ["change"]}, {"source": "Text", "text": "If I commit a change for one template, everything works fine. ", "keywords": ["change"]}]}, {"Id": "263506373", "PostHistoryTypeId": "5", "PostId": "71001123", "RevisionGUID": "d2b8e8e8-68c0-4a4b-b6f0-f7ca1588d18f", "CreationDate": "2022-02-05T20:52:05.660", "UserId": "6046710", "Comment": "added 30 characters in body", "Text": "tldr; I can deploy a single CFN stack as part of my pipeline, but how do I deploy multiple dynamic stacks?\r\n\r\nAn even better tldr; How would you do this? forEach BuildStage.artifact invoke CloudFormation.build \r\n\r\n\r\nI am using CodePipeline in a pretty conventional way. The goal is to source control my CloudFormation templates, push them through the pipeline when a template changes, and then automatically deploy the stack. \r\n\r\nSource Stage (CodeCommit commit my CFN yaml templates)\r\n\r\nBuild Stage (CodeBuild finds the new files from the commit, and pushes them to S3)\r\n\r\nDeploy Stage (CloudFormation deploys my templates as CFN stacks)\r\n\r\n*Almost* everything is working great. I commit my template changes to CodeCommit, the build stage runs my codeBuild gatekeeper, which gathers **only** the files that have changed, and uploads them to S3. So far so good. \r\n\r\nThe challenge is that sometimes I have one template change, and sometimes I have multiple(n). I can detect changed files and get them up to S3 no problem in my build stage. If I commit a change for one template, everything works fine. I can create an exported variable with my template location on S3, pass that to my deploy stage, and have the CloudFormation deploy action use that file as the template source. But how would I handle this if I have 2 templates? \r\n\r\n - I can't just create endless exported variables in my build stage.\r\n - And if I can, AFAIK there is no way to iterate over each entry for the deploy stage.\r\n\r\nMy thought is I would need to do one of the following:\r\n\r\n 1. Inside of my current buildspec (after I upload the files to S3), use the AWS CLI to invoke a CFN stack build. I can add this as part of a loop, so it iterates on each file to be uploaded.  OR\r\n 2. After my build stage, use a Lambda to perform the same as #1. Loop through each file, and then use the CLI or SDK to invoke a CFN stack build.\r\n\r\nBoth of these options seem to defeat the purpose of the deploy stage altogether, which seems clunky to me. \r\n\r\nAre there other options I am missing? What would you do?\r\n\r\n", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "The goal is to source control my CloudFormation templates, push them through the pipeline when a template changes, and then automatically deploy the stack. ", "keywords": ["change"]}, {"source": "Text", "text": "I commit my template changes to CodeCommit, the build stage runs my codeBuild gatekeeper, which gathers **only** the files that have changed, and uploads them to S3. ", "keywords": ["change"]}, {"source": "Text", "text": "The challenge is that sometimes I have one template change, and sometimes I have multiple(n). ", "keywords": ["change"]}, {"source": "Text", "text": "I can detect changed files and get them up to S3 no problem in my build stage. ", "keywords": ["change"]}, {"source": "Text", "text": "If I commit a change for one template, everything works fine. ", "keywords": ["change"]}]}], "answers": [{"Id": "71012765", "PostTypeId": "2", "ParentId": "71001123", "CreationDate": "2022-02-07T01:56:57.660", "Score": "3", "Body": "<p>Just want to answer my own question, in case anyone else is trying to figure out how to do this.</p>\n<p>I ended up going with option 1...just doing a cli CFN deployment directly from within CodeBuild. I was really trying to shoehorn the idea of using a CodePipeline deploy stage, but this works just fine.</p>\n<p>If anyone else ends up coming along with a better solution, I am all ears.</p>\n", "OwnerUserId": "6046710", "LastActivityDate": "2022-02-07T01:56:57.660", "CommentCount": "2", "ContentLicense": "CC BY-SA 4.0", "comments": [{"Id": "125534657", "PostId": "71012765", "Score": "0", "Text": "I'm literally doing that as we speak. The Code Pipeline feels to rigid to me. Like it works for some specific cases, but I'm not super pumped about some of the stuff I need to do in order to deploy. I don't really want to setup a VPC with a NAT Gateway just to deploy. I'm cheap as hell.", "CreationDate": "2022-02-07T03:39:39.270", "UserId": "1248536", "filtered-sentences": [{"source": "Text", "text": "I don't really want to setup a VPC with a NAT Gateway just to deploy. ", "keywords": ["nat"]}, {"source": "Text", "text": "I'm cheap as hell.", "keywords": ["cheap"]}]}, {"Id": "125547394", "PostId": "71012765", "Score": "1", "Text": "I didn't have to do any of that, though my use-case might be different from what you are doing.\n\nI am trying to just push through a handful of CFN templates, and have them auto deploy when they go through the Pipeline.\n\nI created a CodeCommit repo where I push everything to. And then a CodeBuild project that I am really just using to run shell commands to detect only the changed files, copy them to S3, run CFN deploys, etc.. Not the ideal use for CodeBuild, but it is working.", "CreationDate": "2022-02-07T15:07:38.657", "UserId": "6046710", "filtered-sentences": [{"source": "Text", "text": "And then a CodeBuild project that I am really just using to run shell commands to detect only the changed files, copy them to S3, run CFN deploys, etc.. ", "keywords": ["change"]}]}], "history": [{"Id": "263562230", "PostHistoryTypeId": "2", "PostId": "71012765", "RevisionGUID": "cd48351f-58a2-43ce-85f0-c5ff7cebf4c8", "CreationDate": "2022-02-07T01:56:57.660", "UserId": "6046710", "Text": "Just want to answer my own question, in case anyone else is trying to figure out how to do this.\r\n\r\nI ended up going with option 1...just doing a cli CFN deployment directly from within CodeBuild. I was really trying to shoehorn the idea of using a CodePipeline deploy stage, but this works just fine.\r\n\r\nIf anyone else ends up coming along with a better solution, I am all ears.", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "filtered-sentences": []}], "contains-topic": true, "filtered-sentences": [{"source": "Body", "text": "The goal is to source control my CloudFormation templates, push them through the pipeline when a template changes, and then automatically deploy the stack. ", "keywords": ["change"]}, {"source": "Body", "text": "I commit my template changes to CodeCommit, the build stage runs my codeBuild gatekeeper, which gathers only the files that have changed, and uploads them to S3. ", "keywords": ["change"]}, {"source": "Body", "text": "The challenge is that sometimes I have one template change, and sometimes I have multiple(n). ", "keywords": ["change"]}, {"source": "Body", "text": "I can detect changed files and get them up to S3 no problem in my build stage. ", "keywords": ["change"]}, {"source": "Body", "text": "If I commit a change for one template, everything works fine. ", "keywords": ["change"]}]}