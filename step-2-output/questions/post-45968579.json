{"Id": "45968579", "PostTypeId": "1", "CreationDate": "2017-08-30T19:45:57.870", "Score": "0", "ViewCount": "341", "Body": "<p>I have a not-so-complicated situation but it can be complicated on AWS cloudformations:</p>\n\n<p>I would like to autoscale up and down based on the number of messages on SQS. </p>\n\n<p>But I am not sure what I need to specify on AWS cloudformation, I would imagine that I would need:</p>\n\n<ol>\n<li><p>some sort of lambda/cloudformation that perform query on the current number of instances on AutoScalingGroup</p></li>\n<li><p>some sort of lambda/cloudformation that perform query on the current number of messages on SQS. </p></li>\n<li><p>some comparison operations that compares #1 and #2. </p></li>\n<li><p>create scale up policy when #1 &lt; #2</p></li>\n<li><p>create scale down policy when #1 > #2</p></li>\n</ol>\n\n<p>Not sure where I should get started... can someone kind enough to show some examples? </p>\n", "OwnerUserId": "3019766", "LastActivityDate": "2017-08-31T23:24:03.497", "Title": "AutoScaling Based on Comparing Query Metrics", "Tags": "|amazon-web-services|scaling|aws-cloudformation|amazon-sqs|autoscaling|", "AnswerCount": "1", "CommentCount": "0", "ContentLicense": "CC BY-SA 3.0", "history": [{"Id": "155121045", "PostHistoryTypeId": "2", "PostId": "45968579", "RevisionGUID": "90daf6a2-2c91-4c9d-aa65-aefb6ae21aa1", "CreationDate": "2017-08-30T19:45:57.870", "UserId": "3019766", "Text": "I have a not-so-complicated situation but it can be complicated on AWS cloudformations:\r\n\r\nI would like to autoscale up and down based on the number of messages on SQS. \r\n\r\nBut I am not sure what I need to specify on AWS cloudformation, I would imagine that I would need:\r\n\r\n1. some sort of lambda/cloudformation that perform query on the current number of instances on AutoScalingGroup\r\n\r\n2. some sort of lambda/cloudformation that perform query on the current number of messages on SQS. \r\n\r\n3. some comparison operations that compares #1 and #2. \r\n\r\n4. create scale up policy when #1 < #2\r\n\r\n5. create scale down policy when #1 > #2\r\n\r\nNot sure where I should get started... can someone kind enough to show some examples? \r\n\r\n", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "4. create scale up policy when #1 < #2 5. create scale down policy when #1 > #2 Not sure where I should get started... ", "keywords": ["policy"]}]}, {"Id": "155121046", "PostHistoryTypeId": "1", "PostId": "45968579", "RevisionGUID": "90daf6a2-2c91-4c9d-aa65-aefb6ae21aa1", "CreationDate": "2017-08-30T19:45:57.870", "UserId": "3019766", "Text": "AutoScaling Based on Comparing Query Metrics", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "155121047", "PostHistoryTypeId": "3", "PostId": "45968579", "RevisionGUID": "90daf6a2-2c91-4c9d-aa65-aefb6ae21aa1", "CreationDate": "2017-08-30T19:45:57.870", "UserId": "3019766", "Text": "|amazon-web-services|scaling|aws-cloudformation|amazon-sqs|autoscaling|", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}], "answers": [{"Id": "45971377", "PostTypeId": "2", "ParentId": "45968579", "CreationDate": "2017-08-31T00:02:33.627", "Score": "0", "Body": "<p>You have several different concepts all mixed together (CloudFormation, Auto Scaling, Lambda). It is best to <strong>keep things simple</strong>, at least for an initial deployment. You can then automate it with CloudFormation later.</p>\n\n<p>The most difficult part of Auto Scaling is actually <strong>determining the best Scaling Policies to use</strong>. A general rule is to quickly add capacity when it is needed, and then slowly remove capacity when it is no longer needed. This way, you can avoid <em>churn</em>, where instances are added and removed within short spaces of time.</p>\n\n<p>The simplest setup would be:</p>\n\n<ul>\n<li><strong>Scale-out</strong> when the queue size is larger than <strong><em>X</em></strong> (To be determined by testing)</li>\n<li><strong>Scale-in</strong> when the queue is empty (You can later tweak this to be more efficient)</li>\n</ul>\n\n<p>Use the <code>ApproximateNumberOfMessagesVisible</code> metric for your scaling policies. (See <a href=\"http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/sqs-metricscollected.html\" rel=\"nofollow noreferrer\">Amazon SQS Metrics and Dimensions</a>). It provides a count of messages waiting to be processed. However, I have seen situations where a zero count is not actually sent as a metric, so also trigger your scale-in policy on an <strong>alarm status of <em>INSUFFICIENT_DATA</em></strong>, which also means that the queue is empty.</p>\n\n<p>There is <strong>no need to use AWS Lambda functions</strong> unless you have very complex requirements for when to scale.</p>\n\n<p>If your requests come on a <strong>regular basis throughout the day</strong>, set the <strong>minimum</strong> to one instance to always have capacity available.</p>\n\n<p>If your requests are <strong>infrequent</strong> (and there could be several hours with no requests coming in), then set the <strong>minimum</strong> to zero instances so you save money.</p>\n\n<p>You will need to <strong>experiment to determine the best queue size</strong> that should trigger a scale-out event. This depends upon how frequently the messages arrive and how long they take to process. You can also <strong>experiment with the Instance Type</strong> -- figure out whether it is better to have many smaller (eg T2) instances, or fewer larger instances (eg M4 or C4, depending upon need).</p>\n\n<p>If you do not need to process the requests within a short time period (that is, you can be a little late sometimes), you could consider using <strong>spot pricing</strong> that will dramatically lower your costs, with the potential to occasionally have no instances running due to a high spot price. (Or, just bid high and accept that occasionally you'll pay more than on-demand prices but in general you will save considerable costs.)</p>\n\n<p>Create all of the above manually in the console, then experiment and measure results. Once it is finalized, you can then implement it as a <strong>CloudFormation stack</strong> if desired.</p>\n\n<p><strong>Update:</strong></p>\n\n<p>The Auto Scaling screens will only create an alarm based on EC2. To create an alarm on a different metric, first create the alarm, then put it in the policy.</p>\n\n<p>To add a rule based on an Amazon SQS queue:</p>\n\n<ol>\n<li>Create an SQS queue</li>\n<li>Put a message in the queue (otherwise the metrics will not flow through to CloudWatch)</li>\n<li>Create an alarm in CloudWatch based on the <code>ApproximateNumberOfMessagesVisible</code> metric (which will appear after a few minutes)</li>\n<li>Edit your Auto Scaling policies to use the above alarm</li>\n</ol>\n", "OwnerUserId": "174777", "LastEditorUserId": "174777", "LastEditDate": "2017-08-31T23:24:03.497", "LastActivityDate": "2017-08-31T23:24:03.497", "CommentCount": "6", "ContentLicense": "CC BY-SA 3.0", "comments": [{"Id": "78940244", "PostId": "45971377", "Score": "0", "Text": "I'm not sure if I understand what you are saying... as I don't see adding approximateNumberOfMessageVisible as a metric when ScalingUpPolicy adjustment take an integer.\n\n-edit- I think I see TargetTrackingConfiguration, and I'm going to try it.", "CreationDate": "2017-08-31T21:04:17.650", "UserId": "3019766", "filtered-sentences": []}, {"Id": "78969982", "PostId": "45971377", "Score": "0", "Text": "I don't think you actually have done it. Are you aware that if you rely on cloudwatch alarm, then then only time where it is triggered is when approximateNumberOfMessageVisible is reaching to a threshhold? Your \"trigger\" is now a threshhold, not matching the desired number of instances to approximateNumberOfMessageVisible.\n\nFYI, the example here is NOT what I wanted: http://docs.aws.amazon.com/autoscaling/latest/userguide/as-using-sqs-queue.html", "CreationDate": "2017-09-01T16:33:29.517", "UserId": "3019766", "filtered-sentences": []}, {"Id": "78979058", "PostId": "45971377", "Score": "0", "Text": "That is correct. If you assume that an EC2 instance can process A records per minute and records are arriving at B records per minute, then you only want to ADD instances when the rate of message arrival is greater than the rate that messages can be processed. If the queue size grows beyond a given threshold, Auto Scaling will add an instance. This will repeat (after a cooldown period) until the queue size is below the threshold, which means the queue is not growing. It might cause a problem if Minimum = 0 because the first instance won't be added for a while.", "CreationDate": "2017-09-01T23:23:12.890", "UserId": "174777", "filtered-sentences": [{"source": "Text", "text": "If you assume that an EC2 instance can process A records per minute and records are arriving at B records per minute, then you only want to ADD instances when the rate of message arrival is greater than the rate that messages can be processed. ", "keywords": ["instance"]}, {"source": "Text", "text": "If the queue size grows beyond a given threshold, Auto Scaling will add an instance. ", "keywords": ["instance"]}, {"source": "Text", "text": "It might cause a problem if Minimum = 0 because the first instance won't be added for a while.", "keywords": ["instance"]}]}, {"Id": "83369869", "PostId": "45971377", "Score": "0", "Text": "I don't think you understand what I am trying to describe here. The autoscaling metrics only allow you to compare the number of instances to the desired size that you wanted. If it is less than the desired number of instances, it will then spin up new instances. But this is NOT what I wanted. The number of the desired instance is not a fixed number. It is a flexible variable of the number of messages that exist. The number of instances that I would like to spin up (at a rate) is also not a fixed number.", "CreationDate": "2018-01-10T19:19:12.567", "UserId": "3019766", "filtered-sentences": [{"source": "Text", "text": "The number of the desired instance is not a fixed number. ", "keywords": ["instance"]}]}, {"Id": "83379691", "PostId": "45971377", "Score": "0", "Text": "If the queue is big, it means that messages have been arriving faster than they have been processed. Therefore, you want to scale-out (add instances) when the queue is bigger than a certain number. This will increase processing power, therefore reducing the queue size (which represents unprocessed messages). When the queue gets below a certain level (or even zero), you want it to scale-in (remove instances). So, scaling is based on the QUEUE SIZE (a count of messages waiting to be processed) rather than the number of messages arriving.", "CreationDate": "2018-01-11T03:11:20.180", "UserId": "174777", "filtered-sentences": []}, {"Id": "83379712", "PostId": "45971377", "Score": "0", "Text": "See also: [Target Tracking](https://docs.aws.amazon.com/autoscaling/latest/userguide/as-scaling-target-tracking.html), which is relatively new.", "CreationDate": "2018-01-11T03:12:36.723", "UserId": "174777", "filtered-sentences": []}], "history": [{"Id": "155131867", "PostHistoryTypeId": "2", "PostId": "45971377", "RevisionGUID": "e447691e-0c27-406b-9928-cb1898a48252", "CreationDate": "2017-08-31T00:02:33.627", "UserId": "174777", "Text": "You have several different concepts all mixed together (CloudFormation, Auto Scaling, Lambda). It is best to **keep things simple**, at least for an initial deployment. You can then automate it with CloudFormation later.\r\n\r\nThe most difficult part of Auto Scaling is actually **determining the best Scaling Policies to use**. A general rule is to quickly add capacity when it is needed, and then slowly remove capacity when it is no longer needed. This way, you can avoid *churn*, where instances are added and removed within short spaces of time.\r\n\r\nThe simplest setup would be:\r\n\r\n* **Scale-out** when the queue size is larger than ***X*** (To be determined by testing)\r\n* **Scale-in** when the queue is empty (You can later tweak this to be more efficient)\r\n\r\nUse the `ApproximateNumberOfMessagesVisible` metric for your scaling policies. (See [Amazon SQS Metrics and Dimensions](http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/sqs-metricscollected.html)). It provides a count of messages waiting to be processed. However, I have seen situations where a zero count is not actually sent as a metric, so also trigger your scale-in policy on an **alarm status of *INSUFFICIENT_DATA***, which also means that the queue is empty.\r\n\r\nThere is **no need to use AWS Lambda functions** unless you have very complex requirements for when to scale.\r\n\r\nIf your requests come on a **regular basis throughout the day**, set the **minimum** to one instance to always have capacity available.\r\n\r\nIf your requests are **infrequent** (and there could be several hours with no requests coming in), then set the **minimum** to zero instances so you save money.\r\n\r\nYou will need to **experiment to determine the best queue size** that should trigger a scale-out event. This depends upon how frequently the messages arrive and how long they take to process. You can also **experiment with the Instance Type** -- figure out whether it is better to have many smaller (eg T2) instances, or fewer larger instances (eg M4 or C4, depending upon need).\r\n\r\nIf you do not need to process the requests within a short time period (that is, you can be a little late sometimes), you could consider using **spot pricing** that will dramatically lower your costs, with the potential to occasionally have no instances running due to a high spot price. (Or, just bid high and accept that occasionally you'll pay more than on-demand prices but in general you will save considerable costs.)\r\n\r\nCreate all of the above manually in the console, then experiment and measure results. Once it is finalized, you can then implement it as a **CloudFormation stack** if desired.", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "The simplest setup would be: * **Scale-out** when the queue size is larger than ***X*** (To be determined by testing) * **Scale-in** when the queue is empty (You can later tweak this to be more efficient) ", "keywords": ["efficient", "test"]}, {"source": "Text", "text": "However, I have seen situations where a zero count is not actually sent as a metric, so also trigger your scale-in policy on an **alarm status of *INSUFFICIENT_DATA***, which also means that the queue is empty. ", "keywords": ["policy"]}, {"source": "Text", "text": "If your requests come on a **regular basis throughout the day**, set the **minimum** to one instance to always have capacity available. ", "keywords": ["instance"]}, {"source": "Text", "text": "You can also **experiment with the Instance Type** -- figure out whether it is better to have many smaller (eg T2) instances, or fewer larger instances (eg M4 or C4, depending upon need). ", "keywords": ["instance"]}, {"source": "Text", "text": "(Or, just bid high and accept that occasionally you'll pay more than on-demand prices but in general you will save considerable costs.) ", "keywords": ["pay"]}]}, {"Id": "155212332", "PostHistoryTypeId": "5", "PostId": "45971377", "RevisionGUID": "fe037f8c-0437-461f-9eda-2af80ad4ccd1", "CreationDate": "2017-08-31T23:24:03.497", "UserId": "174777", "Comment": "More details", "Text": "You have several different concepts all mixed together (CloudFormation, Auto Scaling, Lambda). It is best to **keep things simple**, at least for an initial deployment. You can then automate it with CloudFormation later.\r\n\r\nThe most difficult part of Auto Scaling is actually **determining the best Scaling Policies to use**. A general rule is to quickly add capacity when it is needed, and then slowly remove capacity when it is no longer needed. This way, you can avoid *churn*, where instances are added and removed within short spaces of time.\r\n\r\nThe simplest setup would be:\r\n\r\n* **Scale-out** when the queue size is larger than ***X*** (To be determined by testing)\r\n* **Scale-in** when the queue is empty (You can later tweak this to be more efficient)\r\n\r\nUse the `ApproximateNumberOfMessagesVisible` metric for your scaling policies. (See [Amazon SQS Metrics and Dimensions](http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/sqs-metricscollected.html)). It provides a count of messages waiting to be processed. However, I have seen situations where a zero count is not actually sent as a metric, so also trigger your scale-in policy on an **alarm status of *INSUFFICIENT_DATA***, which also means that the queue is empty.\r\n\r\nThere is **no need to use AWS Lambda functions** unless you have very complex requirements for when to scale.\r\n\r\nIf your requests come on a **regular basis throughout the day**, set the **minimum** to one instance to always have capacity available.\r\n\r\nIf your requests are **infrequent** (and there could be several hours with no requests coming in), then set the **minimum** to zero instances so you save money.\r\n\r\nYou will need to **experiment to determine the best queue size** that should trigger a scale-out event. This depends upon how frequently the messages arrive and how long they take to process. You can also **experiment with the Instance Type** -- figure out whether it is better to have many smaller (eg T2) instances, or fewer larger instances (eg M4 or C4, depending upon need).\r\n\r\nIf you do not need to process the requests within a short time period (that is, you can be a little late sometimes), you could consider using **spot pricing** that will dramatically lower your costs, with the potential to occasionally have no instances running due to a high spot price. (Or, just bid high and accept that occasionally you'll pay more than on-demand prices but in general you will save considerable costs.)\r\n\r\nCreate all of the above manually in the console, then experiment and measure results. Once it is finalized, you can then implement it as a **CloudFormation stack** if desired.\r\n\r\n**Update:**\r\n\r\nThe Auto Scaling screens will only create an alarm based on EC2. To create an alarm on a different metric, first create the alarm, then put it in the policy.\r\n\r\nTo add a rule based on an Amazon SQS queue:\r\n\r\n1. Create an SQS queue\r\n2. Put a message in the queue (otherwise the metrics will not flow through to CloudWatch)\r\n3. Create an alarm in CloudWatch based on the `ApproximateNumberOfMessagesVisible` metric (which will appear after a few minutes)\r\n4. Edit your Auto Scaling policies to use the above alarm", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "The simplest setup would be: * **Scale-out** when the queue size is larger than ***X*** (To be determined by testing) * **Scale-in** when the queue is empty (You can later tweak this to be more efficient) ", "keywords": ["efficient", "test"]}, {"source": "Text", "text": "However, I have seen situations where a zero count is not actually sent as a metric, so also trigger your scale-in policy on an **alarm status of *INSUFFICIENT_DATA***, which also means that the queue is empty. ", "keywords": ["policy"]}, {"source": "Text", "text": "If your requests come on a **regular basis throughout the day**, set the **minimum** to one instance to always have capacity available. ", "keywords": ["instance"]}, {"source": "Text", "text": "You can also **experiment with the Instance Type** -- figure out whether it is better to have many smaller (eg T2) instances, or fewer larger instances (eg M4 or C4, depending upon need). ", "keywords": ["instance"]}, {"source": "Text", "text": "(Or, just bid high and accept that occasionally you'll pay more than on-demand prices but in general you will save considerable costs.) ", "keywords": ["pay"]}, {"source": "Text", "text": "To create an alarm on a different metric, first create the alarm, then put it in the policy. ", "keywords": ["policy"]}]}], "filtered-sentences": [{"source": "Body", "text": "The simplest setup would be: Scale-out when the queue size is larger than X (To be determined by testing) Scale-in when the queue is empty (You can later tweak this to be more efficient) ", "keywords": ["efficient", "test"]}, {"source": "Body", "text": "However, I have seen situations where a zero count is not actually sent as a metric, so also trigger your scale-in policy on an alarm status of INSUFFICIENT_DATA, which also means that the queue is empty. ", "keywords": ["policy"]}, {"source": "Body", "text": "If your requests come on a regular basis throughout the day, set the minimum to one instance to always have capacity available. ", "keywords": ["instance"]}, {"source": "Body", "text": "You can also experiment with the Instance Type -- figure out whether it is better to have many smaller (eg T2) instances, or fewer larger instances (eg M4 or C4, depending upon need). ", "keywords": ["instance"]}, {"source": "Body", "text": "(Or, just bid high and accept that occasionally you'll pay more than on-demand prices but in general you will save considerable costs.) ", "keywords": ["pay"]}, {"source": "Body", "text": "To create an alarm on a different metric, first create the alarm, then put it in the policy. ", "keywords": ["policy"]}]}], "contains-topic": true, "filtered-sentences": [{"source": "Body", "text": "some comparison operations that compares #1 and #2. create scale up policy when #1 < #2 create scale down policy when #1 > #2 Not sure where I should get started... ", "keywords": ["policy"]}]}